version: "3.8"

# ===========================================
# AI Web Automation Agent - Production Configuration
# ===========================================

services:
  # ===========================================
  # Frontend Service (Production)
  # ===========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
    container_name: ai-automation-frontend-prod
    environment:
      # Frontend Configuration
      - NODE_ENV=production
      - WORKER_URL=http://worker:8000
      - NEXT_PUBLIC_API_URL=${FRONTEND_API_URL:-https://api.yourdomain.com}
      - NEXTAUTH_URL=${FRONTEND_URL:-https://yourdomain.com}
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    depends_on:
      - worker
    restart: unless-stopped
    networks:
      - automation-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================
  # Python Worker Service (Production)
  # ===========================================
  worker:
    build:
      context: ./worker
      dockerfile: Dockerfile
      args:
        - PYTHON_ENV=production
    container_name: ai-automation-worker-prod
    environment:
      # AI Model Configuration
      - AI_MODEL_PROVIDER=${AI_MODEL_PROVIDER:-openai}
      - AI_MODEL_NAME=${AI_MODEL_NAME:-gpt-3.5-turbo}

      # API Keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - HUGGINGFACE_API_TOKEN=${HUGGINGFACE_API_TOKEN}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}

      # LangChain Configuration
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-false}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-selenium-automation-prod}

      # Worker Configuration
      - WORKER_PORT=8000
      - WORKER_HOST=0.0.0.0
      - WORKER_TIMEOUT=${WORKER_TIMEOUT:-300}

      # Selenium Configuration
      - SELENIUM_HEADLESS=true
      - SELENIUM_TIMEOUT=${SELENIUM_TIMEOUT:-60}
      - CHROME_DRIVER_PATH=/usr/local/bin/chromedriver

      # Automation Configuration
      - DEFAULT_FRAMEWORK=${DEFAULT_FRAMEWORK:-selenium}
      - MAX_EXECUTION_TIME=${MAX_EXECUTION_TIME:-300}
      - SCREENSHOT_ON_ERROR=true

      # Production Settings
      - PYTHON_ENV=production
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "${WORKER_PORT:-8000}:8000"
    volumes:
      - worker_screenshots_prod:/app/screenshots
      - worker_projects_prod:/app/generated_projects
      - worker_logs_prod:/app/logs
    restart: unless-stopped
    networks:
      - automation-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================
  # ChromaDB for Vector Storage (Production)
  # ===========================================
  chromadb:
    image: chromadb/chroma:latest
    container_name: ai-automation-chromadb-prod
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_PORT=8001
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
    ports:
      - "${CHROMADB_PORT:-8001}:8001"
    volumes:
      - chromadb_data_prod:/chroma/chroma
    restart: unless-stopped
    networks:
      - automation-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================
  # Ollama Service (Optional - for local models)
  # ===========================================
  ollama:
    image: ollama/ollama:latest
    container_name: ai-automation-ollama-prod
    environment:
      - OLLAMA_HOST=0.0.0.0
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data_prod:/root/.ollama
    restart: unless-stopped
    networks:
      - automation-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Uncomment if you want to use GPU acceleration
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # ===========================================
  # Nginx Reverse Proxy (Optional)
  # ===========================================
  nginx:
    image: nginx:alpine
    container_name: ai-automation-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - worker
    restart: unless-stopped
    networks:
      - automation-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ===========================================
# Persistent Data Volumes (Production)
# ===========================================
volumes:
  worker_screenshots_prod:
    name: ai_automation_screenshots_prod
    driver: local
  worker_projects_prod:
    name: ai_automation_projects_prod
    driver: local
  worker_logs_prod:
    name: ai_automation_logs_prod
    driver: local
  chromadb_data_prod:
    name: ai_automation_chromadb_prod
    driver: local
  ollama_data_prod:
    name: ai_automation_ollama_prod
    driver: local

# ===========================================
# Docker Network Configuration (Production)
# ===========================================
networks:
  automation-network-prod:
    name: ai_automation_network_prod
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16
# ===========================================
# Production Environment Configuration
# ===========================================
#
# Create a .env.prod file with your production settings:
#
# # AI Model Configuration
# AI_MODEL_PROVIDER=openai
# AI_MODEL_NAME=gpt-4
#
# # API Keys (REQUIRED)
# OPENAI_API_KEY=your_production_openai_key
# ANTHROPIC_API_KEY=your_production_anthropic_key
# GOOGLE_API_KEY=your_production_google_key
# HUGGINGFACE_API_TOKEN=your_production_hf_token
#
# # LangChain Configuration
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your_langchain_key
# LANGCHAIN_PROJECT=selenium-automation-prod
#
# # Frontend Configuration
# FRONTEND_URL=https://yourdomain.com
# FRONTEND_API_URL=https://api.yourdomain.com
# NEXTAUTH_SECRET=your_secure_nextauth_secret
#
# # Worker Configuration
# WORKER_TIMEOUT=300
# MAX_EXECUTION_TIME=600
# LOG_LEVEL=INFO
#
# # Port Configuration
# FRONTEND_PORT=3000
# WORKER_PORT=8000
# CHROMADB_PORT=8001
# OLLAMA_PORT=11434
#
# # Security Settings
# SELENIUM_TIMEOUT=120
# DEFAULT_FRAMEWORK=selenium
#
# ===========================================
